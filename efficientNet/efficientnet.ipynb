{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "from collections import OrderedDict\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, Tensor\n",
    "from torchvision.ops import StochasticDepth\n",
    "from torchvision.ops.misc import Conv2dNormActivation, SqueezeExcitation\n",
    "\n",
    "from typing import Any, Callable, List, Optional, Sequence, Tuple, Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_divisible(v: float, divisor: int, min_value: Optional[int] = None) -> int:\n",
    "    \"\"\"\n",
    "    This function is taken from the original tf repo.\n",
    "    It ensures that all layers have a channel number that is divisible by 8\n",
    "    It can be seen here:\n",
    "    https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "    \"\"\"\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def count_parameters(model, showTable=False):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params += params\n",
    "    if showTable:\n",
    "        print(table)\n",
    "    return total_params\n",
    "\n",
    "\n",
    "def calculate_storage(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    print(f\"Buffer size: {buffer_size/1024**2:.3f} MB\")\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    return size_all_mb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MBConv Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        cfg,\n",
    "        stochastic_depth_prob: float,\n",
    "        norm_layer: Callable[..., nn.Module],\n",
    "        se_layer: Optional[Callable[..., nn.Module]] = SqueezeExcitation,\n",
    "        conv_layer: Optional[Callable[..., nn.Module]] = Conv2dNormActivation,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        if not (1 <= cfg.stride <= 2):\n",
    "            raise ValueError(\"illegal stride value\")\n",
    "\n",
    "        self.use_res_connect = (\n",
    "            cfg.stride == 1 and cfg.input_channels == cfg.out_channels\n",
    "        )\n",
    "\n",
    "        layers: List[nn.Module] = []\n",
    "        activation_layer = nn.SiLU\n",
    "\n",
    "        # expand\n",
    "        expanded_channels = cfg.adjust_channels(cfg.input_channels, cfg.expand_ratio)\n",
    "        if expanded_channels != cfg.input_channels:\n",
    "            layers.append(\n",
    "                Conv2dNormActivation(\n",
    "                    cfg.input_channels,\n",
    "                    expanded_channels,\n",
    "                    kernel_size=1,\n",
    "                    norm_layer=norm_layer,\n",
    "                    activation_layer=activation_layer,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        # depthwise\n",
    "        layers.append(\n",
    "            conv_layer(\n",
    "                expanded_channels,\n",
    "                expanded_channels,\n",
    "                kernel_size=cfg.kernel,\n",
    "                stride=cfg.stride,\n",
    "                groups=expanded_channels,\n",
    "                norm_layer=norm_layer,\n",
    "                activation_layer=activation_layer,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # squeeze and excitation\n",
    "        squeeze_channels = max(1, cfg.input_channels // 4)\n",
    "        layers.append(\n",
    "            se_layer(\n",
    "                expanded_channels,\n",
    "                squeeze_channels,\n",
    "                activation=partial(nn.SiLU, inplace=True),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # project\n",
    "        layers.append(\n",
    "            Conv2dNormActivation(\n",
    "                expanded_channels,\n",
    "                cfg.out_channels,\n",
    "                kernel_size=1,\n",
    "                norm_layer=norm_layer,\n",
    "                activation_layer=None,\n",
    "            )\n",
    "        )\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "        self.stochastic_depth = StochasticDepth(stochastic_depth_prob, \"row\")\n",
    "        self.out_channels = cfg.out_channels\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        result = self.block(input)\n",
    "        if self.use_res_connect:\n",
    "            result = self.stochastic_depth(result)\n",
    "            result += input\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MBConv configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class _MBConvConfig:\n",
    "    expand_ratio: float\n",
    "    kernel: int\n",
    "    stride: int\n",
    "    input_channels: int\n",
    "    out_channels: int\n",
    "    num_layers: int\n",
    "    dropout_p: float \n",
    "    use_skip: bool # skip connection between encoder and decoder\n",
    "    block: Callable[..., nn.Module]\n",
    "\n",
    "    @staticmethod\n",
    "    def adjust_channels(\n",
    "        channels: int, width_mult: float, min_value: Optional[int] = None\n",
    "    ) -> int:\n",
    "        return _make_divisible(channels * width_mult, 8, min_value)\n",
    "\n",
    "    @staticmethod\n",
    "    def adjust_depth(num_layers: int, depth_mult: float):\n",
    "        return int(math.ceil(num_layers * depth_mult))\n",
    "\n",
    "\n",
    "class MBConvConfig(_MBConvConfig):\n",
    "    # Stores information listed at Table 1 of the EfficientNet paper\n",
    "    def __init__(\n",
    "        self,\n",
    "        expand_ratio: float,\n",
    "        kernel: int,\n",
    "        stride: int,\n",
    "        input_channels: int,\n",
    "        out_channels: int,\n",
    "        num_layers: int,\n",
    "        dropout_p: float,\n",
    "        use_skip: bool,\n",
    "        width_mult: float = 1.0,\n",
    "        depth_mult: float = 1.0,\n",
    "        block: Optional[Callable[..., nn.Module]] = MBConv,\n",
    "    ) -> None:\n",
    "        input_channels = self.adjust_channels(input_channels, width_mult)\n",
    "        out_channels = self.adjust_channels(out_channels, width_mult)\n",
    "        num_layers = self.adjust_depth(num_layers, depth_mult)\n",
    "        super().__init__(\n",
    "            expand_ratio,\n",
    "            kernel,\n",
    "            stride,\n",
    "            input_channels,\n",
    "            out_channels,\n",
    "            num_layers,\n",
    "            dropout_p,\n",
    "            use_skip,\n",
    "            block,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _efficientnet_cfg(width_mult: float, depth_mult: float) -> Sequence[MBConvConfig]:\n",
    "    inverted_residual_setting = Sequence[MBConvConfig]\n",
    "\n",
    "    bneck_conf = partial(MBConvConfig, width_mult=width_mult, depth_mult=depth_mult)\n",
    "    inverted_residual_setting = [\n",
    "        #         t, k, s, in, out, n, p, skip\n",
    "        bneck_conf(1, 3, 1, 32, 16, 1, 0, 1),\n",
    "        bneck_conf(6, 3, 2, 16, 24, 2, 0, 1),\n",
    "        bneck_conf(6, 5, 2, 24, 40, 2, 0, 1),\n",
    "        bneck_conf(6, 3, 2, 40, 80, 3, 0, 0),\n",
    "        bneck_conf(6, 5, 1, 80, 112, 3, 0.5, 1),\n",
    "        bneck_conf(6, 5, 2, 112, 192, 4, 0.5, 0),\n",
    "        bneck_conf(6, 3, 1, 192, 320, 1, 0.5, 0),\n",
    "    ]\n",
    "\n",
    "    return inverted_residual_setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "efficient_nets = {\n",
    "    'efficientnet-b0': (1.0, 1.0, 224, 0.2),\n",
    "    'efficientnet-b1': (1.0, 1.1, 240, 0.2),\n",
    "    'efficientnet-b2': (1.1, 1.2, 260, 0.3),\n",
    "    'efficientnet-b3': (1.2, 1.4, 300, 0.3),\n",
    "    'efficientnet-b4': (1.4, 1.8, 380, 0.4),\n",
    "    'efficientnet-b5': (1.6, 2.2, 456, 0.4),\n",
    "    'efficientnet-b6': (1.8, 2.6, 528, 0.5),\n",
    "    'efficientnet-b7': (2.0, 3.1, 600, 0.5),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EfficientNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inverted_residual_setting: Sequence[MBConvConfig],\n",
    "        stochastic_depth_prob: float = 0.2,\n",
    "        num_classes: int = 1000,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = nn.BatchNorm2d,\n",
    "        activation_layer: Optional[Callable[..., nn.Module]] = nn.SiLU,\n",
    "        dropout_layer: Optional[Callable[..., nn.Module]] = nn.Dropout2d,\n",
    "        last_channel: Optional[int] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.inv_res_setting = inverted_residual_setting\n",
    "\n",
    "        encoder: OrderedDict[str, nn.Module] = OrderedDict()\n",
    "\n",
    "        # build first conv layer\n",
    "        firstconv_output_channels = self.inv_res_setting[0].input_channels\n",
    "        encoder[\"conv0\"] = Conv2dNormActivation(\n",
    "            3,\n",
    "            firstconv_output_channels,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            norm_layer=norm_layer,\n",
    "            activation_layer=activation_layer,\n",
    "        )\n",
    "\n",
    "        # build inverted residual blocks\n",
    "        total_stage_blocks = sum(cfg.num_layers for cfg in self.inv_res_setting)\n",
    "        stage_block_id = 0\n",
    "        for i, cfg in enumerate(self.inv_res_setting):\n",
    "            stage: List[nn.Module] = []\n",
    "            for j in range(cfg.num_layers):\n",
    "                # copy to avoid modifications. shallow copy is enough\n",
    "                block_cfg = copy.copy(cfg)\n",
    "\n",
    "                # overwrite info if not the first conv in the stage\n",
    "                if stage:\n",
    "                    block_cfg.input_channels = block_cfg.out_channels\n",
    "                    block_cfg.stride = 1\n",
    "\n",
    "                # adjust stochastic depth probability based on the depth of the stage block\n",
    "                sd_prob = (\n",
    "                    stochastic_depth_prob * float(stage_block_id) / total_stage_blocks\n",
    "                )\n",
    "\n",
    "                stage.append(block_cfg.block(block_cfg, sd_prob, norm_layer))\n",
    "                stage_block_id += 1\n",
    "\n",
    "            if cfg.dropout_p > 0:\n",
    "                stage.append(dropout_layer(cfg.dropout_p))\n",
    "\n",
    "            encoder[f\"stage{i+1}\"] = nn.Sequential(*stage)\n",
    "\n",
    "        # building last several layers\n",
    "        lastconv_input_channels = self.inv_res_setting[-1].out_channels\n",
    "        lastconv_output_channels = (\n",
    "            last_channel if last_channel is not None else 4 * lastconv_input_channels\n",
    "        )\n",
    "        encoder[\"lastConv\"] = Conv2dNormActivation(\n",
    "            lastconv_input_channels,\n",
    "            lastconv_output_channels,\n",
    "            kernel_size=1,\n",
    "            norm_layer=norm_layer,\n",
    "            activation_layer=nn.SiLU,\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=0.2, inplace=True),\n",
    "            nn.Linear(lastconv_output_channels, num_classes),\n",
    "        )\n",
    "\n",
    "        # ========= weight initialization ========\n",
    "        self.encoder = nn.Sequential(encoder)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        features = []\n",
    "\n",
    "        # first conv\n",
    "        x = self.encoder.conv0(x)\n",
    "        print(f\"First conv: {x.shape}\")\n",
    "\n",
    "        # stages\n",
    "        for i, cfg in enumerate(self.inv_res_setting):\n",
    "            x = self.encoder[i + 1](x)\n",
    "            print(f\"Stage{i+1}: {x.shape}\")\n",
    "            if cfg.use_skip:\n",
    "                features.append(x)\n",
    "                print(\"use Skip\")\n",
    "\n",
    "        # last conv\n",
    "        x = self.encoder.lastConv(x)\n",
    "        print(f\"Last conv: {x.shape}\")\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _init_weights(self) -> None:\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input dimension: torch.Size([1, 3, 224, 224])\n",
      "First conv: torch.Size([1, 32, 112, 112])\n",
      "Stage1: torch.Size([1, 16, 112, 112])\n",
      "use Skip\n",
      "Stage2: torch.Size([1, 24, 56, 56])\n",
      "use Skip\n",
      "Stage3: torch.Size([1, 40, 28, 28])\n",
      "use Skip\n",
      "Stage4: torch.Size([1, 80, 14, 14])\n",
      "Stage5: torch.Size([1, 112, 14, 14])\n",
      "use Skip\n",
      "Stage6: torch.Size([1, 192, 7, 7])\n",
      "Stage7: torch.Size([1, 320, 7, 7])\n",
      "Last conv: torch.Size([1, 1280, 7, 7])\n",
      "output dimension: torch.Size([1, 1000])\n",
      "Buffer size: 0.161 MB\n",
      "model size: 20.335 MB\n",
      "Total Trainable Params: 5288548\n"
     ]
    }
   ],
   "source": [
    "net_name = \"efficientnet-b0\"\n",
    "width_mult = efficient_nets[net_name][0]\n",
    "depth_mult = efficient_nets[net_name][1]\n",
    "d = efficient_nets[net_name][2]\n",
    "\n",
    "setting = _efficientnet_cfg(width_mult=width_mult, depth_mult=depth_mult)\n",
    "\n",
    "net = EfficientNet(setting)\n",
    "\n",
    "# test forward pass\n",
    "x_batch = torch.zeros(1, 3, d, d)\n",
    "print(f\"input dimension: {x_batch.shape}\")\n",
    "print(f\"output dimension: {net(x_batch).shape}\")\n",
    "\n",
    "size_all_mb = calculate_storage(net)\n",
    "print(\"model size: {:.3f} MB\".format(size_all_mb))  # 20.335 MB\n",
    "\n",
    "total_params = count_parameters(net, False)\n",
    "print(f\"Total Trainable Params: {total_params}\")  # 5288548"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer size: 0.161 MB\n",
      "model size: 20.335 MB\n",
      "Total Trainable Params: 5288548\n"
     ]
    }
   ],
   "source": [
    "# mobilenet_v2_pretrained = torchvision.models.mobilenet_v2()\n",
    "net_pretrained = torchvision.models.efficientnet_b0()\n",
    "\n",
    "size_all_mb = calculate_storage(net_pretrained)\n",
    "print(\"model size: {:.3f} MB\".format(size_all_mb))  # 13.501 MB\n",
    "\n",
    "total_params = count_parameters(net_pretrained, False)\n",
    "print(f\"Total Trainable Params: {total_params}\")  # 3504872"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build UNet with EfficientNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deconv2dNormActivation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Deconv2dNormActivation(nn.Sequential):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: Union[int, Tuple[int, ...]] = 3,\n",
    "        stride: Union[int, Tuple[int, ...]] = 1,\n",
    "        padding: Optional[Union[int, Tuple[int, ...], str]] = None,\n",
    "        out_pad: Optional[Union[int, Tuple[int, ...]]] = None,\n",
    "        groups: int = 1,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = nn.BatchNorm2d,\n",
    "        activation_layer: Optional[Callable[..., nn.Module]] = nn.ReLU,\n",
    "        inplace: Optional[bool] = True,\n",
    "        dilation: Union[int, Tuple[int, ...]] = 1,\n",
    "        bias: Optional[bool] = None,\n",
    "        conv_layer: Callable[..., nn.Module] = nn.ConvTranspose2d,\n",
    "    ) -> None:\n",
    "        # calculate padding\n",
    "        if padding is None:\n",
    "            if dilation > 1:\n",
    "                padding = dilation * (kernel_size - 1) // 2\n",
    "            else:\n",
    "                padding = kernel_size // 2\n",
    "        # calculate output padding\n",
    "        if out_pad is None:\n",
    "            if stride == 2:\n",
    "                out_pad = 1\n",
    "            else:\n",
    "                out_pad = 0\n",
    "\n",
    "        layers = [\n",
    "            conv_layer(\n",
    "                in_channels,\n",
    "                out_channels,\n",
    "                kernel_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                out_pad,\n",
    "                dilation=dilation,\n",
    "                groups=groups,\n",
    "                bias=bias,\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        if norm_layer is not None:\n",
    "            layers.append(norm_layer(out_channels))\n",
    "\n",
    "        if activation_layer is not None:\n",
    "            params = {} if inplace is None else {\"inplace\": inplace}\n",
    "            layers.append(activation_layer(**params))\n",
    "\n",
    "        super().__init__(*layers)\n",
    "\n",
    "        self.out_channels = out_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet\n",
    "\n",
    "Encoder: EfficientNet, parameterised by MBConvConfig\n",
    "Decoder: Symmetrical blocks, only difference is replacing conv2d with TransposeConv2d\n",
    "\n",
    "Skip connections: indicated in MBConvConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        inverted_residual_setting: Sequence[MBConvConfig],\n",
    "        input_width: int = 224,\n",
    "        stochastic_depth_prob: float = 0.2,\n",
    "        num_classes: int = 1000,\n",
    "        norm_layer: Optional[Callable[..., nn.Module]] = nn.BatchNorm2d,\n",
    "        activation_layer: Optional[Callable[..., nn.Module]] = nn.SiLU,\n",
    "        dropout_layer: Optional[Callable[..., nn.Module]] = nn.Dropout2d,\n",
    "        last_channel: Optional[int] = None,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.inv_res_setting = inverted_residual_setting\n",
    "        self.stochastic_depth_prob = stochastic_depth_prob\n",
    "        self.num_classes = num_classes\n",
    "        self.norm_layer = norm_layer\n",
    "        self.activation_layer = activation_layer\n",
    "        self.dropout_layer = dropout_layer\n",
    "        self.input_width = input_width\n",
    "        self.last_channel = last_channel or self.inv_res_setting[-1].out_channels * 4\n",
    "\n",
    "        self.decoder_config = self._decoder_config()\n",
    "\n",
    "        for c in self.inv_res_setting:\n",
    "            print(c)\n",
    "\n",
    "        print(\"-\" * 20)\n",
    "\n",
    "        for c in self.decoder_config:\n",
    "            print(c)\n",
    "\n",
    "        # return\n",
    "\n",
    "        # ========= Build blocks ==========\n",
    "        encoder: OrderedDict = self._build_encoder()\n",
    "        decoder: OrderedDict = self._build_decoder()\n",
    "        self.encoder = nn.Sequential(encoder)\n",
    "        self.decoder = nn.Sequential(decoder)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        # ========= weight initialization ========\n",
    "        self._init_weights()\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        features = []\n",
    "\n",
    "        # ================= Encoder =================\n",
    "        # first conv\n",
    "        x = self.encoder.conv0(x)\n",
    "        print(f\"First Encoder: {x.shape}\")\n",
    "\n",
    "        # stages\n",
    "        for i, cfg in enumerate(self.inv_res_setting):\n",
    "            x = self.encoder[i + 1](x)\n",
    "            print(f\"Stage{i+1} Encoder: {x.shape}\")\n",
    "            if cfg.use_skip:\n",
    "                features.append(x)\n",
    "                print(f\"Skip connection\")\n",
    "\n",
    "        # last conv\n",
    "        x = self.encoder.lastConv(x)\n",
    "        print(f\"Last Encoder: {x.shape}\")\n",
    "\n",
    "        print(\"---------DECODER----------\")\n",
    "\n",
    "        # ================= Decoder =================\n",
    "        # first deconv\n",
    "        x = self.decoder.deconv0(x)\n",
    "        print(f\"First Decoder: {x.shape}\")\n",
    "\n",
    "        # stages\n",
    "        for i, cfg in enumerate(self.decoder_config):\n",
    "            x = self.decoder[i + 1](x)\n",
    "            print(f\"Stage{i+1} Decoder: {x.shape}\")\n",
    "            if i < len(self.decoder_config) - 1 and self.decoder_config[i + 1].use_skip:\n",
    "                print(f\"Skip connection: {x.shape}, {features[-1].shape}\")\n",
    "                x = torch.cat([x, features.pop()], dim=1)\n",
    "\n",
    "        # last deconv\n",
    "        x = self.decoder.lastDeconv(x)\n",
    "        x = self.softmax(x)\n",
    "        print(\"output: \", x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _decoder_config(self) -> List[MBConvConfig]:\n",
    "        decoder_cfg: List[MBConvConfig] = []\n",
    "        oup = self.inv_res_setting[0].input_channels\n",
    "        skip = 0\n",
    "        for cfg in self.inv_res_setting:\n",
    "            skip = cfg.out_channels if cfg.use_skip else 0\n",
    "            cfg_copy = copy.copy(cfg)\n",
    "            cfg_copy.input_channels = cfg.out_channels + skip\n",
    "            cfg_copy.out_channels = oup\n",
    "            decoder_cfg.append(cfg_copy)\n",
    "\n",
    "            oup = cfg.out_channels\n",
    "\n",
    "        return decoder_cfg[::-1]\n",
    "\n",
    "    def _build_decoder(self) -> OrderedDict:\n",
    "        decoder: OrderedDict[str, nn.Module] = OrderedDict()\n",
    "\n",
    "        out = self.inv_res_setting[-1].out_channels\n",
    "        decoder[\"deconv0\"] = Conv2dNormActivation(\n",
    "            self.last_channel, out, 1, 1, bias=False\n",
    "        )\n",
    "\n",
    "        def compute_out_pad(stage, dim):\n",
    "            for _ in range(stage):\n",
    "                dim = math.ceil(dim / 2)\n",
    "            if dim % 2 == 0:\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "\n",
    "        # build inverted residual blocks\n",
    "        total_stage_blocks = sum(cfg.num_layers for cfg in self.inv_res_setting)\n",
    "        stage_block_id = 0\n",
    "        for i, cfg in enumerate(self.decoder_config):\n",
    "            stage: List[nn.Module] = []\n",
    "            for j in range(cfg.num_layers):\n",
    "                # copy to avoid modifications. shallow copy is enough\n",
    "                block_cfg = copy.copy(cfg)\n",
    "\n",
    "                print(\n",
    "                    f\"Deconv{i+1} out_pad = {compute_out_pad(i + 1, self.input_width)}\"\n",
    "                )\n",
    "                conv_layer = partial(\n",
    "                    Deconv2dNormActivation,\n",
    "                    out_pad=compute_out_pad(i + 1, self.input_width),\n",
    "                )\n",
    "                # overwrite info if not first conv in the stage\n",
    "                if j != 0:\n",
    "                    block_cfg.input_channels = block_cfg.out_channels\n",
    "                    block_cfg.stride = 1\n",
    "                    conv_layer = Conv2dNormActivation\n",
    "\n",
    "                # adjust stochastic depth probability based on the depth of the stage block\n",
    "                sd_prob = (\n",
    "                    self.stochastic_depth_prob\n",
    "                    * float(stage_block_id)\n",
    "                    / total_stage_blocks\n",
    "                )\n",
    "\n",
    "                stage.append(\n",
    "                    block_cfg.block(\n",
    "                        block_cfg,\n",
    "                        sd_prob,\n",
    "                        self.norm_layer,\n",
    "                        conv_layer=conv_layer,\n",
    "                    )\n",
    "                )\n",
    "                stage_block_id += 1\n",
    "\n",
    "            if cfg.dropout_p > 0:\n",
    "                stage.append(self.dropout_layer(cfg.dropout_p))\n",
    "\n",
    "            decoder[f\"stage{i+1}\"] = nn.Sequential(*stage)\n",
    "\n",
    "        # build last deconv\n",
    "        decoder[\"lastDeconv\"] = Deconv2dNormActivation(\n",
    "            self.decoder_config[-1].out_channels,\n",
    "            self.num_classes,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            padding=1,\n",
    "            norm_layer=self.norm_layer,\n",
    "            activation_layer=self.activation_layer,\n",
    "        )\n",
    "        return decoder\n",
    "\n",
    "    def _build_encoder(self) -> OrderedDict:\n",
    "        encoder: OrderedDict[str, nn.Module] = OrderedDict()\n",
    "\n",
    "        # build first conv layer\n",
    "        firstconv_output_channels = self.inv_res_setting[0].input_channels\n",
    "        encoder[\"conv0\"] = Conv2dNormActivation(\n",
    "            3,\n",
    "            firstconv_output_channels,\n",
    "            kernel_size=3,\n",
    "            stride=2,\n",
    "            norm_layer=self.norm_layer,\n",
    "            activation_layer=self.activation_layer,\n",
    "        )\n",
    "\n",
    "        # build inverted residual blocks\n",
    "        total_stage_blocks = sum(cfg.num_layers for cfg in self.inv_res_setting)\n",
    "        stage_block_id = 0\n",
    "        for i, cfg in enumerate(self.inv_res_setting):\n",
    "            stage: List[nn.Module] = []\n",
    "            for j in range(cfg.num_layers):\n",
    "                # copy to avoid modifications. shallow copy is enough\n",
    "                block_cfg = copy.copy(cfg)\n",
    "\n",
    "                # overwrite info if not the first conv in the stage\n",
    "                if stage:\n",
    "                    block_cfg.input_channels = block_cfg.out_channels\n",
    "                    block_cfg.stride = 1\n",
    "\n",
    "                # adjust stochastic depth probability based on the depth of the stage block\n",
    "                sd_prob = (\n",
    "                    self.stochastic_depth_prob\n",
    "                    * float(stage_block_id)\n",
    "                    / total_stage_blocks\n",
    "                )\n",
    "\n",
    "                stage.append(block_cfg.block(block_cfg, sd_prob, self.norm_layer))\n",
    "                stage_block_id += 1\n",
    "\n",
    "            if cfg.dropout_p > 0:\n",
    "                stage.append(self.dropout_layer(cfg.dropout_p))\n",
    "\n",
    "            encoder[f\"stage{i+1}\"] = nn.Sequential(*stage)\n",
    "\n",
    "        # build last several layers\n",
    "        lastconv_input_channels = self.inv_res_setting[-1].out_channels\n",
    "        lastconv_output_channels = self.last_channel\n",
    "        encoder[\"lastConv\"] = Conv2dNormActivation(\n",
    "            lastconv_input_channels,\n",
    "            lastconv_output_channels,\n",
    "            kernel_size=1,\n",
    "            norm_layer=self.norm_layer,\n",
    "            activation_layer=nn.SiLU,\n",
    "        )\n",
    "        return encoder\n",
    "\n",
    "    def _init_weights(self) -> None:\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode=\"fan_out\")\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.ConvTranspose2d):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBConvConfig(expand_ratio=1, kernel=3, stride=1, input_channels=32, out_channels=16, num_layers=2, dropout_p=0, use_skip=1, block=<class '__main__.MBConv'>)\n",
      "MBConvConfig(expand_ratio=6, kernel=3, stride=2, input_channels=16, out_channels=24, num_layers=3, dropout_p=0, use_skip=1, block=<class '__main__.MBConv'>)\n",
      "MBConvConfig(expand_ratio=6, kernel=5, stride=2, input_channels=24, out_channels=48, num_layers=3, dropout_p=0, use_skip=1, block=<class '__main__.MBConv'>)\n",
      "MBConvConfig(expand_ratio=6, kernel=3, stride=2, input_channels=48, out_channels=88, num_layers=4, dropout_p=0, use_skip=0, block=<class '__main__.MBConv'>)\n",
      "MBConvConfig(expand_ratio=6, kernel=5, stride=1, input_channels=88, out_channels=120, num_layers=4, dropout_p=0.5, use_skip=1, block=<class '__main__.MBConv'>)\n",
      "MBConvConfig(expand_ratio=6, kernel=5, stride=2, input_channels=120, out_channels=208, num_layers=5, dropout_p=0.5, use_skip=0, block=<class '__main__.MBConv'>)\n",
      "MBConvConfig(expand_ratio=6, kernel=3, stride=1, input_channels=208, out_channels=352, num_layers=2, dropout_p=0.5, use_skip=0, block=<class '__main__.MBConv'>)\n",
      "--------------------\n",
      "MBConvConfig(expand_ratio=6, kernel=3, stride=1, input_channels=352, out_channels=208, num_layers=2, dropout_p=0.5, use_skip=0, block=<class '__main__.MBConv'>)\n",
      "MBConvConfig(expand_ratio=6, kernel=5, stride=2, input_channels=208, out_channels=120, num_layers=5, dropout_p=0.5, use_skip=0, block=<class '__main__.MBConv'>)\n",
      "MBConvConfig(expand_ratio=6, kernel=5, stride=1, input_channels=240, out_channels=88, num_layers=4, dropout_p=0.5, use_skip=1, block=<class '__main__.MBConv'>)\n",
      "MBConvConfig(expand_ratio=6, kernel=3, stride=2, input_channels=88, out_channels=48, num_layers=4, dropout_p=0, use_skip=0, block=<class '__main__.MBConv'>)\n",
      "MBConvConfig(expand_ratio=6, kernel=5, stride=2, input_channels=96, out_channels=24, num_layers=3, dropout_p=0, use_skip=1, block=<class '__main__.MBConv'>)\n",
      "MBConvConfig(expand_ratio=6, kernel=3, stride=2, input_channels=48, out_channels=16, num_layers=3, dropout_p=0, use_skip=1, block=<class '__main__.MBConv'>)\n",
      "MBConvConfig(expand_ratio=1, kernel=3, stride=1, input_channels=32, out_channels=32, num_layers=2, dropout_p=0, use_skip=1, block=<class '__main__.MBConv'>)\n",
      "Deconv1 out_pad = 1\n",
      "Deconv1 out_pad = 1\n",
      "Deconv2 out_pad = 0\n",
      "Deconv2 out_pad = 0\n",
      "Deconv2 out_pad = 0\n",
      "Deconv2 out_pad = 0\n",
      "Deconv2 out_pad = 0\n",
      "Deconv3 out_pad = 0\n",
      "Deconv3 out_pad = 0\n",
      "Deconv3 out_pad = 0\n",
      "Deconv3 out_pad = 0\n",
      "Deconv4 out_pad = 0\n",
      "Deconv4 out_pad = 0\n",
      "Deconv4 out_pad = 0\n",
      "Deconv4 out_pad = 0\n",
      "Deconv5 out_pad = 0\n",
      "Deconv5 out_pad = 0\n",
      "Deconv5 out_pad = 0\n",
      "Deconv6 out_pad = 0\n",
      "Deconv6 out_pad = 0\n",
      "Deconv6 out_pad = 0\n",
      "Deconv7 out_pad = 0\n",
      "Deconv7 out_pad = 0\n",
      "input dimension: torch.Size([1, 3, 260, 260])\n",
      "First Encoder: torch.Size([1, 32, 130, 130])\n",
      "Stage1 Encoder: torch.Size([1, 16, 130, 130])\n",
      "Skip connection\n",
      "Stage2 Encoder: torch.Size([1, 24, 65, 65])\n",
      "Skip connection\n",
      "Stage3 Encoder: torch.Size([1, 48, 33, 33])\n",
      "Skip connection\n",
      "Stage4 Encoder: torch.Size([1, 88, 17, 17])\n",
      "Stage5 Encoder: torch.Size([1, 120, 17, 17])\n",
      "Skip connection\n",
      "Stage6 Encoder: torch.Size([1, 208, 9, 9])\n",
      "Stage7 Encoder: torch.Size([1, 352, 9, 9])\n",
      "Last Encoder: torch.Size([1, 1408, 9, 9])\n",
      "---------DECODER----------\n",
      "First Decoder: torch.Size([1, 352, 9, 9])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "output padding must be smaller than either stride or dilation, but got output_padding_height: 1 output_padding_width: 1 stride_height: 1 stride_width: 1 dilation_height: 1 dilation_width: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m x_batch \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn(\u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, d, d)\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minput dimension: \u001b[39m\u001b[39m{\u001b[39;00mx_batch\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39moutput dimension: \u001b[39m\u001b[39m{\u001b[39;00mnet(x_batch)\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SNet_torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[157], line 75\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39m# stages\u001b[39;00m\n\u001b[1;32m     74\u001b[0m \u001b[39mfor\u001b[39;00m i, cfg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder_config):\n\u001b[0;32m---> 75\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder[i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m](x)\n\u001b[1;32m     76\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mStage\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m Decoder: \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m     \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder_config) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder_config[i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\u001b[39m.\u001b[39muse_skip:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SNet_torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SNet_torch/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SNet_torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[5], line 74\u001b[0m, in \u001b[0;36mMBConv.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 74\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_res_connect:\n\u001b[1;32m     76\u001b[0m         result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstochastic_depth(result)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SNet_torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SNet_torch/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SNet_torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SNet_torch/lib/python3.9/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SNet_torch/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/SNet_torch/lib/python3.9/site-packages/torch/nn/modules/conv.py:956\u001b[0m, in \u001b[0;36mConvTranspose2d.forward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m    951\u001b[0m num_spatial_dims \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    952\u001b[0m output_padding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_padding(\n\u001b[1;32m    953\u001b[0m     \u001b[39minput\u001b[39m, output_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkernel_size,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    954\u001b[0m     num_spatial_dims, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m--> 956\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv_transpose2d(\n\u001b[1;32m    957\u001b[0m     \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding,\n\u001b[1;32m    958\u001b[0m     output_padding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: output padding must be smaller than either stride or dilation, but got output_padding_height: 1 output_padding_width: 1 stride_height: 1 stride_width: 1 dilation_height: 1 dilation_width: 1"
     ]
    }
   ],
   "source": [
    "net_name = \"efficientnet-b2\"\n",
    "width_mult = efficient_nets[net_name][0]\n",
    "depth_mult = efficient_nets[net_name][1]\n",
    "d = efficient_nets[net_name][2]\n",
    "\n",
    "setting = _efficientnet_cfg(width_mult=width_mult, depth_mult=depth_mult)\n",
    "\n",
    "net = UNet(setting, input_width=d, num_classes=3)\n",
    "\n",
    "x_batch = torch.randn(1, 3, d, d)\n",
    "print(f\"input dimension: {x_batch.shape}\")\n",
    "print(f\"output dimension: {net(x_batch).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----ENCODER----\n",
      "Buffer size: 0.161 MB\n",
      "model size: 15.448MB\n",
      "Total Trainable Params: 4007548\n",
      "----DECODER----\n",
      "Buffer size: 0.154 MB\n",
      "model size: 15.194MB\n",
      "Total Trainable Params: 3942596\n",
      "----UNET----\n",
      "Buffer size: 0.315 MB\n",
      "model size: 30.642MB\n",
      "Total Trainable Params: 7950144\n"
     ]
    }
   ],
   "source": [
    "print(\"----ENCODER----\")\n",
    "size_all_mb = calculate_storage(net.encoder)\n",
    "print(\"model size: {:.3f}MB\".format(size_all_mb))\n",
    "total_params = count_parameters(net.encoder)\n",
    "print(f\"Total Trainable Params: {total_params}\")\n",
    "\n",
    "\n",
    "print(\"----DECODER----\")\n",
    "size_all_mb = calculate_storage(net.decoder)\n",
    "print(\"model size: {:.3f}MB\".format(size_all_mb))\n",
    "total_params = count_parameters(net.decoder)\n",
    "print(f\"Total Trainable Params: {total_params}\")\n",
    "\n",
    "\n",
    "print(\"----UNET----\")\n",
    "size_all_mb = calculate_storage(net)\n",
    "print(\"model size: {:.3f}MB\".format(size_all_mb))\n",
    "total_params = count_parameters(net)\n",
    "print(f\"Total Trainable Params: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SNet_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
